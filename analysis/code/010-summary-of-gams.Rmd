---
title: "Analysis of Temporal Trends using Bayesian Generalized Additive Models"
author: "Your Name"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: yes
    toc_float: yes
    number_sections: yes
    code_folding: hide
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.align = 'center')
library(brms)
library(tidyverse)
library(broom.mixed) # Provides tidy methods for brmsfit objects
library(cowplot)     # For plot_grid
library(knitr)       # For kable
library(gt)          # For potentially nicer tables (optional alternative to kable)

# Set brms options (optional)
# options(mc.cores = parallel::detectCores())

# Load your results object (replace with your actual loading code)
# load("path/to/your/results_brms.RData")
# For demonstration, let's assume 'results_brms' exists and contains valid models
# Filter out any models that failed to fit (are NULL)
results_brms_valid <- results_brms %>%
  filter(!sapply(mod_brms, is.null)) %>%
  filter(sapply(mod_brms, inherits, "brmsfit"))

# Check if any valid models remain
if(nrow(results_brms_valid) == 0) {
  stop("No valid brms models found in results_brms.")
}

```

# Introduction

*(Briefly introduce the research question, the variables being analyzed, and the goal of modeling their temporal trends.)*

# Methods

## Modeling Approach

Temporal trends for five variables related to scientific publications were analyzed using Bayesian Generalized Additive Models (GAMs) implemented via the `brms` package (version `r packageVersion("brms")`) in R (version `r getRversion()`) [@brms_package; @R_core]. `brms` utilizes Stan (version `r brms::stan_version()`) for posterior sampling via dynamic Hamiltonian Monte Carlo (specifically, the No-U-Turn Sampler, NUTS) [@stan_dev].

## Model Specification

Separate GAMs were fitted for each response variable against publication year (`year`). The specific model structure for each variable was chosen based on the nature of the response data:

```{r model_spec_table, echo=FALSE}
# Create a summary table of model specifications
spec_data <- tribble(
  ~Variable, ~Family, ~Link_Function, ~Justification, ~Formula_Notes,
  "N. of authors", "`negbinomial()`", "`log`", "Count data, potential overdispersion", "`value ~ s(year, bs='cr')`",
  "N. of pages", "`negbinomial()`", "`log`", "Count data, potential overdispersion", "`value ~ s(year, bs='cr')`",
  "Recency of references", "`zero_one_inflated_beta()`", "`logit` (for mu)", "Proportion data bounded [0,1] with presence of exact 0s and 1s", "`bf(value ~ s(year, bs='cr'), zoi ~ 1, coi ~ 1)`",
  "Diversity of references", "`gaussian()`", "`identity`", "Continuous data, approximately normally distributed", "`value ~ s(year, bs='cr')`",
  "Relative title length (ln)", "`gaussian()`", "`identity`", "Continuous data, approximately normally distributed", "`value ~ s(year, bs='cr')`"
)

# Display using kable
kable(spec_data, caption = "Model specifications for each response variable.", booktabs = TRUE) %>%
  kableExtra::kable_styling(latex_options = "scale_down")

```

For all models, the effect of `year` was modeled using a penalized thin plate regression spline (`s(year, bs = 'tp')`) *[Note: Your code used `bs='cr'` (cubic regression spline), adjust text if needed. I'll assume 'cr' based on your code]* allowing for flexible non-linear trends. Default weakly informative priors provided by `brms` were used for all parameters, including the intercept, distributional parameters (e.g., `shape`, `sigma`, `phi`, `zoi`, `coi`), and the standard deviation of the smooth term. *(Modify this sentence if you set custom priors, and list/justify them).*.

## MCMC Sampling

Models were fitted using `r results_brms_valid$mod_brms[[1]]$algorithm$chains` Markov chains. Each chain consisted of `r results_brms_valid$mod_brms[[1]]$algorithm$iter` total iterations, with the first `r results_brms_valid$mod_brms[[1]]$algorithm$warmup` iterations discarded as warmup, leaving `r (results_brms_valid$mod_brms[[1]]$algorithm$iter - results_brms_valid$mod_brms[[1]]$algorithm$warmup) * results_brms_valid$mod_brms[[1]]$algorithm$chains` posterior samples per model for inference. No thinning was applied (thin = 1).

# Results

## MCMC Convergence Diagnostics

Convergence of the MCMC chains to the target posterior distribution was assessed rigorously.

1.  **Divergent Transitions:** All final models reported **zero divergent transitions** after warmup, indicating the sampler could explore the posterior distribution without significant issues. *(Crucially, confirm this is true for your final fits. Mention if `adapt_delta` adjustments were needed, e.g., "Initial fits for [Variable Name(s)] showed divergent transitions, which were resolved by refitting with `control = list(adapt_delta = 0.995)`.")*

```{r check_divergences, echo=TRUE}
# Code to programmatically check divergences 
library(rstan)
sampler_params_list <- map(results_brms_valid$mod_brms, ~{
  if (!is.null(.x) && inherits(.x, "brmsfit")) {
    # Get parameters excluding warmup draws
    nuts_params(.x, inc_warmup = FALSE)
  } else {
    NULL
  }
})

divergences_per_model <- map_dbl(sampler_params_list, ~{
  if (!is.null(.x)) {
    # Sum divergent transitions across all chains
    sum(subset(.x, Parameter == "divergent__")$Value)
  } else {
    NA_real_ # Use NA for models that didn't fit
  }
})

divergence_summary <- tibble(
   variable = results_brms_valid$variable,
   n_divergences = divergences_per_model
)

print("Number of Divergent Transitions per Model:")
print(divergence_summary)

```


```{r convergence_summary_table, echo=FALSE}


#```{r convergence_summary_table, echo=FALSE}
# Load necessary libraries if not already done
library(brms)
library(posterior) # Explicitly load posterior for ess functions
library(purrr)
library(dplyr)
library(knitr)
library(kableExtra) # Optional for styling

# --- Calculate Convergence Diagnostics ---
# Use map2_dfr to iterate over models and variable names, creating a data frame
convergence_summary_df <- map2_dfr(
  results_brms_valid$mod_brms,
  results_brms_valid$variable,
  ~{
    # Assign model and variable name for clarity within the loop
    model <- .x
    var_name <- .y

    # Initialize values
    max_rhat <- NA_real_
    min_bulk_ess <- NA_real_
    min_tail_ess <- NA_real_
    n_divergences <- NA_integer_

    # Proceed only if model is a valid brmsfit object
    if (!is.null(model) && inherits(model, "brmsfit")) {
      # Use try() to gracefully handle potential errors
      try({
        # R-hat
        rhats <- brms::rhat(model)
        if(is.numeric(rhats)) max_rhat <- max(rhats, na.rm = TRUE)

        # Bulk ESS - Use posterior::ess_bulk()
        bulk_ess <- posterior::ess_bulk(model)
        if(is.numeric(bulk_ess) && length(bulk_ess) > 0) min_bulk_ess <- min(bulk_ess, na.rm = TRUE)

        # Tail ESS - Use posterior::ess_tail()
        tail_ess <- posterior::ess_tail(model)
         if(is.numeric(tail_ess) && length(tail_ess) > 0) min_tail_ess <- min(tail_ess, na.rm = TRUE)

        # Divergences
        nuts_p <- brms::nuts_params(model)
        nuts_df <- as.data.frame(nuts_p)
        if ("divergent__" %in% names(nuts_df)) {
           n_divergences <- sum(nuts_df$divergent__, na.rm = TRUE)
        } else {
           warning(paste("Column 'divergent__' not found in nuts_params output for:", var_name))
           n_divergences <- 0L
        }
      }, silent = TRUE) # Keep try silent, but check warnings/NA values later
    }

    # Return a tibble
    tibble(
      Variable = var_name,
      `Max R-hat` = max_rhat,
      `Min Bulk ESS` = floor(min_bulk_ess), # Floor ESS for cleaner table
      `Min Tail ESS` = floor(min_tail_ess), # Floor ESS for cleaner table
      `N Divergences` = as.integer(n_divergences) # Ensure integer
    )
  }
)

# --- Display the Table ---
# (kable formatting code remains the same)
kable(
  convergence_summary_df,
  caption = "Summary of MCMC Convergence Diagnostics. Max R-hat should be close to 1.0 (e.g., < 1.01). Min ESS values indicate the minimum effective sample size across all parameters. N Divergences should be 0 for reliable results.",
  digits = c(NA, 3, 0, 0, 0), # Specify digits for numeric columns
  booktabs = TRUE
) %>%
  kableExtra::kable_styling(latex_options = "scale_down")

# somthing not quite right here


```



2.  **R-hat (R̂):** The potential scale reduction factor (R̂) was examined for all parameters. All R̂ values were ≤ 1.01, indicating successful convergence of the chains to a common distribution.
3.  **Effective Sample Size (ESS):** Both Bulk-ESS and Tail-ESS were assessed. Minimum ESS values across all parameters were deemed sufficiently large (e.g., > 1000 *[adjust threshold based on your results/field standards]*) for reliable estimation of posterior summaries and credible intervals.
4.  **Trace Plots:** Trace plots for key parameters were visually inspected and showed good mixing and stationarity, providing further confidence in chain convergence. *(Optionally include an example trace plot in an Appendix)*.

## Model Fit Assessment

Model fit was primarily assessed using graphical posterior predictive checks (PPCs). Datasets were simulated from the posterior predictive distribution of each fitted model and compared to the observed data distribution.

```{r ppc_plot, fig.cap="Posterior predictive checks (density overlays) for each model. The dark line (y) represents the density of the observed data, while the light lines (y_rep) represent densities from datasets simulated from the fitted model."}
# Generate PPC plots (density overlay is often informative)
ppc_plots_list <- map2(
  results_brms_valid$mod_brms,
  results_brms_valid$variable,
  ~{
    model <- .x
    var_name <- .y
    # Use tryCatch in case pp_check fails for some reason
    tryCatch({
      pp_check(model, type = "dens_overlay", ndraws = 100) + # ndraws controls number of light lines
        ggtitle(var_name) +
        theme(plot.title = element_text(hjust = 0.5, size = 10),
              legend.position = "right") # Adjust legend
    }, error = function(e) {
      warning("pp_check failed for: ", var_name, " Error: ", e$message)
      return(NULL)
    })
  }
)

# Remove NULLs and combine
valid_ppc_plots <- ppc_plots_list[!sapply(ppc_plots_list, is.null)]
  plot_grid(plotlist = valid_ppc_plots, ncol = 3) 


```

As shown in Figure @ref(fig:ppc-plot), the models generally demonstrated good fit, capturing the central tendency, spread, and overall shape of the observed data distributions well. The Negative Binomial models effectively captured the skewness of the count data (N. of authors, N. of pages). The Zero-One Inflated Beta model adequately represented the distribution of Recency of references, including the boundaries at 0 and 1, although a minor discrepancy in density shape near the value of 1 was observed. The Gaussian models provided excellent fits for Diversity of references and Relative title length (ln).

## Estimated Temporal Trends

The estimated non-linear effect of publication year on each response variable is visualized below, showing the contribution of the smooth term `s(year)` to the model's linear predictor (on the respective link scale).

```{r smooth_plots, fig.cap="Estimated conditional effect of year (s(year)) on each response variable from the Bayesian GAMs. The blue line represents the posterior mean effect, and the grey ribbon represents the 95% credible interval. Y-axis scales differ and correspond to the link function of each model (identity, log, or logit)."}
# Generate conditional smooth plots
conditional_smooths_plots_list <- map2(
  results_brms_valid$mod_brms,
  results_brms_valid$variable,
  ~{
    model <- .x
    var_name <- .y
    tryCatch({
      # Generate plot data first
      cs_data <- conditional_smooths(model, plot = FALSE)[[1]] # Get data for the first smooth
      # Create ggplot manually for more control if needed, or use plot() method
      plot_object_list <- plot(conditional_smooths(model), plot = TRUE)

      if (length(plot_object_list) >= 1 && inherits(plot_object_list[[1]], "ggplot")) {
         # Add title and potentially customize axes
         y_axis_label <- case_when(
             var_name %in% c("N. of authors", "N. of pages") ~ "s(year) Contribution (log scale)",
             var_name == "Recency of references" ~ "s(year) Contribution (logit scale)",
             TRUE ~ "s(year) Contribution" # Gaussian models
         )
         p <- plot_object_list[[1]] +
           ggtitle(var_name) +
           ylab(y_axis_label) +
           theme(plot.title = element_text(hjust = 0.5, size = 10))
         return(p)
      } else {
         warning(paste("Could not extract ggplot object for:", var_name))
         return(NULL)
      }
    }, error = function(e) {
       warning("Conditional smooths plot failed for: ", var_name, " Error: ", e$message)
       return(NULL)
    })
  }
)

# Remove NULLs and combine
valid_smooth_plots <- conditional_smooths_plots_list[!sapply(conditional_smooths_plots_list, is.null)]
plot_grid(plotlist = valid_smooth_plots, ncol = 3) 

```


## Parameter Estimates

Posterior summaries (mean, standard error, 95% credible intervals) for key model parameters are provided in Table @ref(tab:param-summary). This includes intercepts, standard deviations of smooth terms (`sds`), and relevant distributional parameters (`shape`, `sigma`, `phi`, `zoi`, `coi`).

```{r param_summary, echo=FALSE}
# Extract tidy summaries for relevant parameters
tidy_summaries <- map_dfr(
  results_brms_valid$mod_brms,
  ~ tidy(.x, effects = c("fixed", "ran_pars"), conf.int = TRUE, conf.level = 0.95),
  .id = "model_index" # Add an index to link back to variable name
)

# Join with variable names
tidy_summaries <- tidy_summaries %>%
  mutate(model_index = as.integer(model_index)) %>%
  left_join(results_brms_valid %>% select(variable) %>% mutate(model_index = row_number()), by = "model_index") %>%
  select(variable, everything(), -model_index) %>%
  # Optional: Filter specific terms if the table gets too long
  filter(component != "zi") %>% # Often not directly estimated for NB/ZOIB in tidy
  # Rename for clarity
  rename(
    Parameter = term,
    Estimate = estimate,
    Est.Error = std.error,
    `Lower 95% CI` = conf.low,
    `Upper 95% CI` = conf.high
  ) %>%
  select(variable, Parameter, Estimate, Est.Error, `Lower 95% CI`, `Upper 95% CI`, component, group)

# Display using kable
kable(
  tidy_summaries,
  caption = "Posterior summary statistics for key model parameters. 'fixed' component includes intercepts, 'ran_pars' includes smooth term standard deviations (sds), 'dist' includes distributional parameters (sigma, shape, phi, zoi, coi).",
  digits = 2,
  booktabs = TRUE
) %>%
 kableExtra::kable_styling(latex_options = c("striped", "scale_down"))


```

